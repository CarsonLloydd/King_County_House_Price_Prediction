{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from pyearth import Earth\n",
    "\n",
    "import gc; gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_Housing_Data_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'price'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cols = ['sqft_living', 'lat', 'long',  'sqft_lot', 'year']\n",
    "cat_cols = ['bedrooms', 'bathrooms', 'grade', 'view', 'condition', 'month', 'yr_built', 'zipcode', 'yr_renovated']\n",
    "used_cols =  real_cols + cat_cols\n",
    "# used_cols = [c for c in df.columns.tolist() if c not in [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[used_cols], df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
       "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s(0) + s(1) + s(2) + s(3) + s(4) + te(1, 2) + te(0, 1, 2) + te(5, 6) + te(1, 2, 12) + f(5) + f(6) + f(7) + f(8) + f(9) + f(10) + f(11) + f(12) + f(13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function gc.collect>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pygam.terms import s as spline\n",
    "from pygam.terms import f as factor\n",
    "from pygam.terms import te as tensor\n",
    "\n",
    "\n",
    "# DEFINE TERMS:\n",
    "#   * splines - for continuous\n",
    "#   * factors - for categorical/discrete \n",
    "#        (assumption: label encoded w/ 0 to level_size-1)\n",
    "#   * tensors - for any interactions\n",
    "\n",
    "# create the term list\n",
    "term_list = []\n",
    "for i, col in enumerate(used_cols):\n",
    "    if col in real_cols:\n",
    "        term_list.append(spline(i))\n",
    "\n",
    "# add the x1 and x2 interaction term\n",
    "term_list.append(tensor(1, 2))\n",
    "term_list.append(tensor(0, 1, 2))\n",
    "term_list.append(tensor(5, 6))\n",
    "term_list.append(tensor(1, 2, 12))\n",
    "# term_list.append(tensor(7, 8, 10))\n",
    "# term_list.append(tensor(0, 4))\n",
    "# term_list.append(tensor(0, 1, 2, 3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# factors\n",
    "for i, col in enumerate(used_cols):\n",
    "    if col in cat_cols:\n",
    "        term_list.append(factor(i))\n",
    "\n",
    "\n",
    "# create the terms and model\n",
    "terms = np.sum(term_list)\n",
    "print(terms)\n",
    "gc.collect\n",
    "# gam = LinearGAM(terms=terms).gridsearch(X.values, y.values)\n",
    "# gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (11 of 11) |########################| Elapsed Time: 0:11:21 Time:  0:11:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAM                                                                                                       \n",
      "=============================================== ==========================================================\n",
      "Distribution:                         GammaDist Effective DoF:                                    498.1882\n",
      "Link Function:                          LogLink Log Likelihood:                               -269427.3384\n",
      "Number of Samples:                        21263 AIC:                                           539853.0532\n",
      "                                                AICc:                                          539877.1047\n",
      "                                                GCV:                                                0.0296\n",
      "                                                Scale:                                              0.0287\n",
      "                                                Pseudo R-Squared:                                   0.9067\n",
      "==========================================================================================================\n",
      "Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n",
      "================================= ==================== ============ ============ ============ ============\n",
      "s(0)                              [0.001]              20           19.7         8.44e-04     ***         \n",
      "s(1)                              [0.001]              20           18.9         1.11e-16     ***         \n",
      "s(2)                              [0.001]              20           18.6         1.11e-16     ***         \n",
      "s(3)                              [0.001]              20           18.8         1.11e-16     ***         \n",
      "s(4)                              [0.001]              20           1.3          1.11e-16     ***         \n",
      "te(1, 2)                          [0.001 0.001]        100          54.2         1.11e-16     ***         \n",
      "te(0, 1, 2)                       [0.001 0.001 0.001]  1000         185.8        1.11e-16     ***         \n",
      "te(5, 6)                          [0.001 0.001]        100          29.3         1.11e-16     ***         \n",
      "te(1, 2, 12)                      [0.001 0.001 0.001]  1000         91.0         1.11e-16     ***         \n",
      "f(5)                              [0.001]              5            0.0          1.11e-16     ***         \n",
      "f(6)                              [0.001]              26           7.2          1.11e-16     ***         \n",
      "f(7)                              [0.001]              11           3.0          1.11e-16     ***         \n",
      "f(8)                              [0.001]              5            1.6          1.11e-16     ***         \n",
      "f(9)                              [0.001]              5            1.7          1.11e-16     ***         \n",
      "f(10)                             [0.001]              12           4.6          1.11e-16     ***         \n",
      "f(11)                             [0.001]              116          39.9         1.11e-16     ***         \n",
      "f(12)                             [0.001]              70           0.0          1.11e-16     ***         \n",
      "f(13)                             [0.001]              6            2.6          1.11e-16     ***         \n",
      "intercept                                              1            0.0          1.11e-16     ***         \n",
      "==========================================================================================================\n",
      "Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n",
      "         which can cause p-values to appear significant when they are not.\n",
      "\n",
      "WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n",
      "         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n",
      "         are typically lower than they should be, meaning that the tests reject the null too readily.\n"
     ]
    }
   ],
   "source": [
    "# Playing with distribution assumptions and link functions\n",
    "from pygam import GAM\n",
    "\n",
    "\n",
    "gam = GAM(terms=terms, distribution='gamma', link='log')\n",
    "gam.gridsearch(X.values, y.values)\n",
    "gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error train:  67701.13973314365\n",
      "mean absolute error test:  68310.64716546224\n",
      "r2 predict train:  0.8818973591337486\n",
      "r2 predict test:  0.8788013603039673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0, train_size = .7)\n",
    "# Define model\n",
    "# Fit model\n",
    "# gam.fit(train_X, train_y)\n",
    "#get predicted prices on validation data\n",
    "val_predictions = gam.predict(val_X)\n",
    "train_predictions = gam.predict(train_X)\n",
    "print(\"mean absolute error train: \" , mean_absolute_error(train_y, train_predictions))\n",
    "print(\"mean absolute error test: \" , mean_absolute_error(val_y, val_predictions))\n",
    "print(\"r2 predict train: \" , r2_score(train_y, train_predictions))\n",
    "print(\"r2 predict test: \" , r2_score(val_y, val_predictions))\n",
    "#print(cross_val_score(gam, train_X, train_y, cv=3, scoring = 'r2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_col_gams.sav']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'all_col_gams.sav'\n",
    "joblib.dump(gam, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
