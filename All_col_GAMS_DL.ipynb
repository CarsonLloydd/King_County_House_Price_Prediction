{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from pyearth import Earth\n",
    "\n",
    "import gc; gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_Housing_Data_vDL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'price'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cols = ['sqft_living', 'lat', 'long',  'sqft_lot', 'year']\n",
    "cat_cols = ['bedrooms', 'bathrooms', 'grade', 'view', 'condition', 'month', 'yr_built', 'zipcode', 'yr_renovated']\n",
    "used_cols =  real_cols + cat_cols\n",
    "# used_cols = [c for c in df.columns.tolist() if c not in [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[used_cols], df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'date', 'price', 'bedrooms', 'bathrooms',\n",
       "       'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition',\n",
       "       'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
       "       'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'year',\n",
       "       'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s(0) + s(1) + s(2) + s(3) + s(4) + te(1, 2) + te(0, 1, 2) + te(5, 6) + te(1, 2, 12) + f(5) + f(6) + f(7) + f(8) + f(9) + f(10) + f(11) + f(12) + f(13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function gc.collect>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pygam.terms import s as spline\n",
    "from pygam.terms import f as factor\n",
    "from pygam.terms import te as tensor\n",
    "\n",
    "\n",
    "# DEFINE TERMS:\n",
    "#   * splines - for continuous\n",
    "#   * factors - for categorical/discrete \n",
    "#        (assumption: label encoded w/ 0 to level_size-1)\n",
    "#   * tensors - for any interactions\n",
    "\n",
    "# create the term list\n",
    "term_list = []\n",
    "for i, col in enumerate(used_cols):\n",
    "    if col in real_cols:\n",
    "        term_list.append(spline(i))\n",
    "\n",
    "# add the x1 and x2 interaction term\n",
    "term_list.append(tensor(1, 2))\n",
    "term_list.append(tensor(0, 1, 2))\n",
    "term_list.append(tensor(5, 6))\n",
    "term_list.append(tensor(1, 2, 12))\n",
    "# term_list.append(tensor(7, 8, 10))\n",
    "# term_list.append(tensor(0, 4))\n",
    "# term_list.append(tensor(0, 1, 2, 3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# factors\n",
    "for i, col in enumerate(used_cols):\n",
    "    if col in cat_cols:\n",
    "        term_list.append(factor(i))\n",
    "\n",
    "\n",
    "# create the terms and model\n",
    "terms = np.sum(term_list)\n",
    "print(terms)\n",
    "gc.collect\n",
    "# gam = LinearGAM(terms=terms).gridsearch(X.values, y.values)\n",
    "# gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:10:41 ETA:   0:01:05"
     ]
    }
   ],
   "source": [
    "# Playing with distribution assumptions and link functions\n",
    "from pygam import GAM\n",
    "\n",
    "\n",
    "gam = GAM(terms=terms, distribution='gamma', link='log')\n",
    "gam.gridsearch(X.values, y.values)\n",
    "gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error train:  67701.13973314365\n",
      "mean absolute error test:  68310.64716546224\n",
      "r2 predict train:  0.8818973591337486\n",
      "r2 predict test:  0.8788013603039673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0, train_size = .7)\n",
    "# Define model\n",
    "# Fit model\n",
    "# gam.fit(train_X, train_y)\n",
    "#get predicted prices on validation data\n",
    "val_predictions = gam.predict(val_X)\n",
    "train_predictions = gam.predict(train_X)\n",
    "print(\"mean absolute error train: \" , mean_absolute_error(train_y, train_predictions))\n",
    "print(\"mean absolute error test: \" , mean_absolute_error(val_y, val_predictions))\n",
    "print(\"r2 predict train: \" , r2_score(train_y, train_predictions))\n",
    "print(\"r2 predict test: \" , r2_score(val_y, val_predictions))\n",
    "#print(cross_val_score(gam, train_X, train_y, cv=3, scoring = 'r2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_col_gams.sav']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'all_col_gams.sav'\n",
    "joblib.dump(gam, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
